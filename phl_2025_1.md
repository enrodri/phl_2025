```python
# 1. IMPORTS
# ==========================================
# %matplotlib inline
import pandas as pd
import numpy as np
import plotly.graph_objects as go
import matplotlib.pyplot as plt
import statsmodels.api as sm
from sklearn.metrics import roc_curve, auc
from sklearn.linear_model import LinearRegression
import seaborn as sns
import re
import missingno as msno
import os
from IPython.display import display, Markdown
```


```python
# 2. DICTIONARIES AND LISTS
# ==========================================

# * These dictionaries and lists act as the "Medical Brain" of the script. 

# Separating logic from data allows non-coders to update clinical criteria easily.
class ClinicalConfig:
    """
    Centralized configuration object acting as the 'Medical Brain'.
    Encapsulates all clinical dictionaries, regex patterns, decision boundaries,
    and biological sanity checks.
    """
    def __init__(self):
        # 1. Variable Categorization
        self.categories = {
            "Demographics/Vitals": ['Age', 'Gender', 'Weight', 'Height', 'OSat', 'SBP R', 'DBP R', 'Heart rate'],
            "Medications": ['Medications'],
            "Clinical Context": ['Pre-procedure diagnosis', 'Post-procedure diagnosis', 'Year(s) since procedure'],
            "Structural Echo (Dimensions)": ['IVSd', 'LVIDd', 'LVPWd', 'LVIDs', 'Aortic root', 'Left atrium measure', 'Left atrium'],
            "Functional Echo (Hemodynamics)": ['LVEF (categorical)', 'RVSP', 'TR Vmax', 'AO V1 max', 'AO V2 max', 'MS MG (mmHg)']
        }

        # 2. Severity & Scoring Maps
        self.severity = {
            'critical': 3.5, 'severe to critical': 3.25, 'severe': 3.0,
            'moderate to severe': 2.5, 'moderate': 2.0, 'mild to moderate': 1.5,
            'mild': 1.0, 'none': 0.0
        }
        
        self.lvef_values = {
            'Hyperdynamic': 70.0, 'Normal': 60.0, 'Borderline': 50.0,
            'Moderately reduced': 40.0, 'Reduced': 25.0
        }
        
        self.echo_severity = {'trace': 15.0, 'mild': 20.0, 'none': 10.0}

        # 3. Pattern Recognition (Regex Targets)
        self.procedures = {
            "Surgical" : ['replacement', 'repair', 'patch', 'graft'],
            "Percutaneous" : ['percutaneous valvuloplasty', 'closure', 'stent', 'ablation']
        }

        self.pathology_patterns = {
            'MS': ['mitral stenosis'],
            'MR': ['mitral regurgitation'],
            'AS':  ['aortic stenosis'],
            'AR': ['aortic regurgitation'],
            'PH': ['pulmonary hypertension'],
            'Septal': ['Secundum atrial septal defect', 'Perimembranous ventricular septal defect', 
                       'Ventricular septal defect', 'Incomplete atrioventricular septal defect', 'Sinus venosus atrial septal defect']
        }
        
        self.la_patterns = {
            4.0: r'(?:huge|severely|severe)',
            2.5: r'(?:moderately|moderate)',
            1.0: r'(?:mild)'
        }

        # 4. Pharmacological Knowledge Base
        self.medication_classes = {
            'Beta_Blockers': ['Carvedilol', 'Bisoprolol', 'Propranolol', 'Metoprolol', 'Atenolol'],
            'RAAS_Inhibitors': ['Enalapril', 'Lisinopril', 'Losartan', 'Valsartan', 'Irbesartan', 'Captopril', 'Sacubitril-valsartan'],
            'Diuretics_Loop': ['Furosemide'],
            'Diuretics_Other': ['Spironolactone', 'Espironolactone', 'Hydrochlorothiazide'],
            'Anticoagulants_Antiplatelets': ['Warfarin', 'Warfarine', 'Rivaroxaban', 'Apixaban', 'Aspirin', 'Clopidogrel'],
            'Rate_Rhythm_Control': ['Digoxin', 'Amiodarone'],
            'Calcium_Channel_Blockers': ['Nifedipine', 'Amlodipine'],
            'SGLT2_Inhibitors': ['Dapaglifozin', 'Empaglifozin'],
            'Pulmonary_Vasodilators': ['Sildenafil', 'Tadalafil'],
            'Lipid_Lowering': ['Simvastatin', 'Rosuvastatin', 'Rosuvastatine', 'Gemfibrozil', 'Ciprofibrate'],
            'Anti_Ischemic_Other': ['Trimetazidine', 'Ranolazine'],
            'Metabolic_Endocrine': ['Levothyroxine', 'Metformin']
        }

        self.freq_day = {'qd': 1, 'bid': 2, 'tid': 3, 'qid': 4}

        self.max_doses = {
            'Sacubitril-valsartan': 400.0, 'Enalapril': 40.0, 'Lisinopril': 40.0, 'Losartan': 100.0,
            'Valsartan': 320.0, 'Irbesartan': 300.0, 'Captopril': 150.0, 'Carvedilol': 50.0,
            'Bisoprolol': 10.0, 'Metoprolol': 200.0, 'Atenolol': 100.0, 'Propranolol': 160.0,
            'Furosemide': 80.0, 'Spironolactone': 50.0, 'Hydrochlorothiazide': 25.0,
            'Sildenafil': 60.0, 'Tadalafil': 40.0, 'Digoxin': 0.25, 'Amiodarone': 400.0,
            'Warfarin': 5.0, 'Rivaroxaban': 20.0, 'Apixaban': 10.0, 'Aspirin': 100.0,
            'Clopidogrel': 75.0, 'Nifedipine': 90.0, 'Amlodipine': 10.0, 'Trimetazidine': 70.0,
            'Ranolazine': 1000.0, 'Dapaglifozin': 10.0, 'Empaglifozin': 25.0, 'Metformin': 2000.0,
            'Levothyroxine': 0.2, 'Simvastatin': 40.0, 'Rosuvastatin': 40.0, 'Gemfibrozil': 1200.0,
            'Ciprofibrate': 100.0
        }

        self.class_weights = {
            'Diuretics_Loop': 3.0, 'Pulmonary_Vasodilators': 3.0, 'RAAS_Inhibitors': 2.0,
            'SGLT2_Inhibitors': 2.0, 'Diuretics_Other': 2.0, 'Beta_Blockers': 2.0,
            'Rate_Rhythm_Control': 1.0, 'Anticoagulants_Antiplatelets': 1.0,
            'Calcium_Channel_Blockers': 1.0, 'Anti_Ischemic_Other': 1.0,
            'Lipid_Lowering': 0.5, 'Metabolic_Endocrine': 0.5
        }

        # 5. Analysis Groupings
        self.echo_groups = {
            "Mitral": {"Parameters": ['MS MG (mmHg)', 'Left atrium', 'LVIDd', 'LVIDs'], "Severity_Cols": ['Sev_MS', 'Sev_MR']},
            "Aortic": {"Parameters": ['AO V1 max', 'AO V2 max', 'Aortic root', 'IVSd', 'LVPWd'], "Severity_Cols": ['Sev_AS', 'Sev_AR']},
            "PH": {"Parameters": ['RVSP', 'TR Vmax'], "Severity_Cols": ['Sev_PH']}
        }
        
        self.echo_vars = ['MS MG (mmHg)', 'AO V2 max', 'RVSP', 'Left atrium', 'LVIDd', 'LVEF (categorical)']
        self.echo_missing = ['MS MG (mmHg)', 'AO V2 max', 'RVSP', 'LVIDd']

        # 6. Statistical Baselines & Sanity Checks
        self.normal_variables = {
            'MS MG (mmHg)': (1.5, 0.5),
            'AO V2 max': (1.1, 0.2),
            'RVSP': (25.0, 4.0),
            'LVIDd': (46.0, 4.0)
        }
        
        # Biological Sanity Checks (Clamping Limits)
        self.sanity_checks = {
            'RVSP': (0.0, 200.0),       # Pulmonary pressure shouldn't exceed 200
            'LVIDd': (10.0, 100.0),     # LV diameter in mm
            'MS MG (mmHg)': (0.0, 60.0) # Mean gradient
        }
```


```python
# 3. CLASSES AND FUNCTIONS
# ==========================================

class Auditor:
    """
    Acts as the 'Quality Control' station. 
    Before any analysis, we must identify 'Missing Not At Random' (MNAR) patterns 
    often caused by limited time during medical brigades.
    """
    def __init__(self, dataframe, config):
        self.df = dataframe.copy()
        self.config = config

    def report(self):
        """
        Generates a 3-part audit: 
        1. Technical metadata.
        2. Clinical category missingness (shows which exam parts were skipped).
        3. Lexicon extraction (identifies unique raw strings for manual review).
        """
        audit = []
        for col in self.df.columns:
            audit.append({
                'Column': col,
                'Inferred dtype': self.df[col].dtype,
                'Null Count': self.df[col].isnull().sum(),
                'Sample Values': self.df[col].dropna().unique()[:3].tolist()
            })
            
        # Clinical NLP: Extracting the vocabulary used by the doctors in the field.
        all_diagnoses = pd.concat([
            self.df['Pre-procedure diagnosis'],
            self.df['Post-procedure diagnosis']
        ]).str.split(',').explode().str.strip().dropna().unique()

        all_medications = self.df['Medications'].str.split('|').explode().str.strip().dropna()
        medications_unique = all_medications.str.split(' ').str[0].str.capitalize().unique()

        # Reporting Missingness by Clinical Grouping
        print(f"Current columns by category:\n{'-'*40}")
        for category, cols in self.config.categories.items():
            print(f"{category}: {cols}")

        group_report = {}
        missing_from_categories = []

        for group, cols in self.config.categories.items():
            # Checks if our expected columns actually exist in the CSV header
            not_found = [c for c in cols if c not in self.df.columns]
            found = [c for c in cols if c in self.df.columns]

            # This logs missing columns
            if not_found:
                missing_from_categories.extend(not_found)
                print(f"\nWarning in {group}: Missing from CSV: {not_found}")
                
            # This calculates mean missingness for found columns
            if found:
                avg_miss = self.df[found].isnull().mean().mean() * 100
                group_report[group] = f"{avg_miss:.2f}% missing"
            else:
                group_report[group] = "N/A - No columns found"

        print("\nMean missingness by category (%):")
        print(f"{'-'*40}")
        print(pd.Series(group_report))

        # Persistence: Ensuring we have an 'Audit Trail' for clinical accountability.
        audit_df = pd.DataFrame(audit)
        pd.DataFrame({'All_diagnoses_list': all_diagnoses}).to_csv('all_diagnoses_report.csv', index=False)
        pd.DataFrame({'All_medications_list': medications_unique}).to_csv('all_medications_report.csv', index=False)
        audit_df.to_csv('dataset_audit_report.csv', index=False)

        print('\nAudit report generated:\n' + f"{'-'*40}")
        print('Technical metadata file generated: dataset_audit_report.csv. ')
        print('All unique diagnoses list generated: all_diagnoses_report.csv.')
        print('All medications list generated: all_medications_report.csv.')
        return audit_df
        
    def echo_missingness(self):
        """
        Forensic Data Audit: 
        Calculates completion rates (%) per column, stratified by 
        disease severity and clinical grouping.
        """
        results = []
        
        # Access the injected echo_groups_dict
        for unit, groups in self.config.echo_groups.items():
            for sev_col in groups["Severity_Cols"]: 
                if sev_col not in self.df.columns:
                    continue
                
                for sev_level in sorted(self.df[sev_col].unique()):
                    subset = self.df[self.df[sev_col] == sev_level]
                    if subset.empty: continue
                    
                    for param in groups["Parameters"]:
                        if param in self.df.columns:
                            completeness = (1 - subset[param].isnull().mean()) * 100
                            results.append({
                                'Pathology': sev_col.replace('Sev_', ''),
                                'Severity': sev_level,
                                'Parameter': param,
                                'Completeness_Pct': round(completeness, 2),
                                'N': len(subset)
                            })
                            
        missings_stratified = pd.DataFrame(results)

        # Pivot for 'Triage Matrix' visualization. 
        pivot_audit = missings_stratified.pivot_table(
            index=['Pathology', 'Parameter'], 
            columns='Severity', 
            values='Completeness_Pct' 
        )
        
        print("Triage proxy pivot table" + "\n" + "-"*40)
        print("Rows: Pathology-Parameter pairs")
        print("Columns: Clinical Severity (0.0 to 3.5)\n")
        return pivot_audit

class Extractor:
    """
    The 'Refinery'. Transforms messy clinical strings into 'Tidy' structured data.
    Key philosophy: Do not oversimplify. Preserve mixed valvular disease signatures.
    """
    def __init__(self, dataframe, config):
        self.df = dataframe.copy()
        self.config = config
        self.severities = list(self.config.severity.keys())
        # Regex to strip intensity
        self.strip_pattern = r'\b(' + '|'.join(self.severities) + r')\b'

    def _get_expanded_diag(self, col_name):
        """Handles comma-separated lists in a single cell."""
        return self.df[col_name].str.lower().str.split(',').explode().str.strip().dropna()

    def _clean_column(self, col):
        """Standardizes anatomy by removing qualitative noise and surgical terms."""
        s = self._get_expanded_diag(col)
        cleaned = s.str.replace(self.strip_pattern, '', regex=True) \
            .str.replace(r'\s+', ' ', regex=True) \
            .str.strip() \
            .str.capitalize()
        
        # Group back to original rows to maintain 1:1 patient mapping.
        return cleaned.groupby(level=0).agg(lambda x: ', '.join(x.unique()) if x.any() else np.nan)

    def _parse_meds(self, med_string, drug_list):
        """
        Pharmacological Parser:
        Identifies drug, extracts base dose, and applies frequency multipliers (e.g., bid=x2).
        """
        if pd.isna(med_string) or med_string == "":
            return "None", 0.0
            
        individual_meds = [m.strip().lower() for m in str(med_string).split('|')]
        
        for med_entry in individual_meds:
            matched_drug = next((d for d in drug_list if d.lower() in med_entry), None)
            
            if matched_drug:
                # Extract dose number (handles decimals like 6.25)
                dose_match = re.search(r'(\d+\.?\d*)', med_entry)
                base_dose = float(dose_match.group(1)) if dose_match else 0.0
                
                # Determine frequency multiplier
                multiplier = 1 
                for freq, value in self.config.freq_day.items():
                    if f" {freq}" in f" {med_entry}":
                        multiplier = value
                        break
                
                return matched_drug.capitalize(), base_dose * multiplier
                
        return "None", 0.0

    def transform(self):
        """
        Main orchestration of the feature engineering process.
        Creates a multidimensional lesion matrix (e.g., separate columns for MS and MR severity).
        """
        # 1. Anatomy Extraction (The 'What' is involved)
        self.df['Anatomy_Pre'] = self._clean_column('Pre-procedure diagnosis')
        self.df['Anatomy_Post'] = self._clean_column('Post-procedure diagnosis')

        # 2. Multidimensional Severity Mapping (The 'How Bad' is it?)
        def severity_score(text_series, path_regex):
            entries = str(text_series).lower().split(',')
            for entry in entries:
                if re.search(path_regex, entry):
                    for label, score in self.config.severity.items():
                        if label in entry: return score
            return 0.0

        for lesion, keywords in self.config.pathology_patterns.items():
            col_name = f'Sev_{lesion}'
            pattern = '|'.join(keywords) 
            self.df[col_name] = self.df['Pre-procedure diagnosis'].fillna('').apply(
                lambda x: severity_score(x, pattern)
            )

        # 3. Procedural Classification (The 'Approach')
        self.df['Approach'] = 'Native'
        post_exploded = self._get_expanded_diag('Post-procedure diagnosis')
        
        for group, keywords in self.config.procedures.items():
            pattern = '|'.join(keywords)
            idx = post_exploded[post_exploded.str.contains(pattern, regex=True, na=False)].index
            self.df.loc[idx, 'Approach'] = group

        # 4. Pharmacological Quantification
        for category, drugs in self.config.medication_classes.items():
            name_col = f"{category}_name"
            dose_col = f"{category}_tdd"
            
            # Use the internal _parse_meds method with injected freq_day
            self.df[[name_col, dose_col]] = self.df['Medications'].apply(
                lambda x: pd.Series(self._parse_meds(x, drugs))
            )

        # 5. Left Atrium Size Scoring
        self.df['LA_Size_Score'] = 0.0
        self.df['LA_Thrombus'] = 0
        self.df['LA_Mass'] = 0
        
        for score, pattern in self.config.la_patterns.items():
            # Only update if current score is lower (preserves the highest severity found)
            mask = self.df['Left atrium'].str.contains(pattern, case=False, na=False, regex=True)
            self.df.loc[mask, 'LA_Size_Score'] = np.maximum(self.df.loc[mask, 'LA_Size_Score'], score)

        # 6. Pathological Findings (Flags)
        # Thrombus/Clot/Smoke (Spontaneous Echo Contrast)
        self.df['LA_Thrombus'] = self.df['Left atrium'].str.contains(r'(?:thrombus)', case=False, na=False, regex=True).astype(int)

        # Masses (Myxomas)
        self.df['LA_Mass'] = self.df['Left atrium'].str.contains(r'(?:myxoma)', case=False, na=False, regex=True).astype(int)
        
        # 6. Normalization of echo 
        for col in self.config.echo_missing:
            if col in self.df.columns:
                # 1. Convert to string and handle whitespace
                # We use .str.strip() to catch hidden spaces like " 25 "
                s = self.df[col].astype(str).str.lower().str.strip()
                
                # 2. Replace qualitative terms (trace, mild) with your dictionary
                s = s.replace(self.config.echo_severity)
                
                # 3. Final Coercion
                # If a value was "45mm", pd.to_numeric turns it to NaN. 
                # If your data has "mm" in it, we must strip it first.
                s = s.str.replace(r'[^0-9.]', '', regex=True) # Remove all non-numeric chars
                
                self.df[col] = pd.to_numeric(s, errors='coerce')

        # 7. LVEF Numerical Mapping
        # We use .str.title() to match 'Normal', 'Reduced', etc. 
        if 'LVEF (categorical)' in self.df.columns:
            self.df['LVEF_Score'] = self.df['LVEF (categorical)'].str.strip().str.title().map(self.config.lvef_values)
            
            # Clinical Safety Check: If "Moderately reduced" has a lowercase 'r', 
            # title() makes it "Moderately Reduced". We adjust the map or use a lambda.
            # Best practice: 
            self.df['LVEF_Score'] = self.df['LVEF (categorical)'].str.strip().map(
                {k: v for k, v in self.config.lvef_values.items()} # Direct map
            ).fillna(self.df['LVEF (categorical)'].str.strip().str.capitalize().map(self.config.lvef_values))
            
        return self.df

    def diagnoses_prevalence(self):
        """Standardizes and counts the global disease burden in the cohort."""
        # Note: transform() must be called before this method to generate Anatomy_Pre
        if 'Anatomy_Pre' not in self.df.columns:
             raise ValueError("Please run transform() first.")
        
        pre = self.df['Anatomy_Pre'].str.split(', ').explode()
        post = self.df['Anatomy_Post'].str.split(', ').explode()
        return pd.concat([pre, post]).value_counts()
        
    def disease_profiler(self):
        '''
        Identifies complex interactions: Mixed Lesions, Shunts, and Rhythm Confounders.
        '''
        if 'Sev_MS' not in self.df.columns:
             raise ValueError("Please run transform() with required dictionaries before running disease_profiler()")

        # 1. Mixed Valvular Disease (Same-valve: Stenosis + Regurgitation)
        self.df['Mixed_Mitral'] = ((self.df['Sev_MS'] > 0) & (self.df['Sev_MR'] > 0)).astype(int)
        self.df['Mixed_Aortic'] = ((self.df['Sev_AS'] > 0) & (self.df['Sev_AR'] > 0)).astype(int)

        # 2. Multi-Valvular Disease (Cross-valve: Mitral unit AND Aortic unit)
        mitral_any = (self.df['Sev_MS'] > 0) | (self.df['Sev_MR'] > 0)
        aortic_any = (self.df['Sev_AS'] > 0) | (self.df['Sev_AR'] > 0)
        self.df['Multi_Valve'] = (mitral_any & aortic_any).astype(int)

        # 3. Pulmonary Hypertension (Explicit Flag)
        # Defined here as any PH mention (Severity > 0)
        self.df['PH_Present'] = (self.df['Sev_PH'] > 0).astype(int)

        # 4. Shunts (Septal Defects)
        shunt_pattern = '|'.join(self.config.pathology_patterns['Septal'])
        self.df['Has_Shunt'] = self.df['Pre-procedure diagnosis'].str.contains(
            shunt_pattern, case=False, na=False, regex=True
        ).astype(int)

        # 5. Rhythm Confounders (AFib)
        self.df['AFib_Present'] = self.df['Pre-procedure diagnosis'].str.contains(
            'Atrial fibrillation', case=False, na=False, regex=True
        ).astype(int)

        # 6. Global Complexity Score 
        # Summing binary flags. Note: For PH, we only count it as a 'Complexity Point' 
        # if it is Moderate or worse (>= 2.0), as Mild PH is very common.
        self.df['Complexity_Score'] = (
            self.df['Mixed_Mitral'] + 
            self.df['Mixed_Aortic'] + 
            self.df['Multi_Valve'] + 
            self.df['Has_Shunt'] + 
            self.df['AFib_Present'] + 
            (self.df['Sev_PH'] >= 2.0).astype(int)
        )

        # Accurate Prevalence Reporting
        self.complexity_stats = {
            "Total Patients": len(self.df),
            "Mixed Mitral": self.df['Mixed_Mitral'].sum(),
            "Mixed Aortic": self.df['Mixed_Aortic'].sum(),
            "Multi-Valvular": self.df['Multi_Valve'].sum(),
            "Any PH Mention": self.df['PH_Present'].sum(),
            "AFib Present": self.df['AFib_Present'].sum()
        }
        
        return self.df
        
    def complexity_report(self):
        """
        Returns the stats as a clean Pandas Series for easy display or export.
        """
        print("Complex cases\n" + '-'*40)
        print("Cases that have either mixed, multiple valvular disease and/or other conditions\n")
        if hasattr(self, 'complexity_stats'):
            return pd.Series(self.complexity_stats, name="Prevalence")
        else:
            return "Profiler has not been run yet."

class Calculator:
    def __init__(self, dataframe, config):
        self.df = dataframe.copy()
        self.config = config

    def medication_index(self):
        """
        Computes the Medication Burden Index (MBI).
        MBI = Sum(Class_Weight * (Actual_TDD / Max_TDD))
        """
        self.df['MBI'] = 0.0
        
        for category, weight in self.config.class_weights.items():
            name_col = f"{category}_name"
            dose_col = f"{category}_tdd"
            
            if name_col in self.df.columns:
                # Vectorized calculation for each class
                # Uses 1.0 as a fallback intensity for fixed-dose meds (like Aspirin)
                intensity = self.df.apply(
                    lambda x: x[dose_col] / self.config.max_doses.get(x[name_col], x[dose_col]) 
                    if x[dose_col] > 0 else 0, axis=1
                )
                
                # Clips intensity at 1.0 (to avoid outliers from rare supra-therapeutic doses)
                self.df['MBI'] += (intensity.clip(upper=1.0) * weight)
                
        return self.df
    
class Visualizer:
    def __init__(self, dataframe):
        self.df = dataframe.copy()
        
    def patient_nullity(self, target_columns):
        # Forensic Audit: Visualizing data deserts to evaluate mission-specific documentation constraints.
        available_keys = [v for v in target_columns if v in self.df.columns]

        # Uses a temporary theme context to ensure the 'Matrix' is readable

        # We use a context manager to temporarily ignore the 'whitegrid' theme
        # which can interfere with missingno's rendering.
        with plt.style.context('default'):
            plt.figure(figsize=(10, 6))
            msno.matrix(self.df[available_keys], 
                        sparkline=False, 
                        color=(0.1, 0.3, 0.5), # Your dark blue
                        fontsize=10)
            plt.title("Nullity Matrix: Data Presence (Dark) vs Missing (White)", fontsize=14)
            plt.show()

        print("Correlation of Missingness (1.0 = Always missing together):" + "\n" + "-"*40)
        # Heatmap usually works better with a standard context too
        with plt.style.context('default'):
            msno.heatmap(self.df[available_keys], cmap='GnBu')
            plt.title("Missingness Correlation")
            plt.show()

    def echo_matrix(self, table):
        # Triage Efficiency: Quantifying which physiological parameters are deemed 'Critical Path' by the field team.
        print("\nEchocardiogram Triage Matrix notes:" + "\n" + "-"*40)
        print("A 'Hot' cell (High %) indicates a parameter the cardiologist deemed mandatory for triage.")
        
        plt.figure(figsize=(14, 10))
        # Using a sequential colormap (YlOrRd) to highlight 'Data Deserts' vs 'Data Oases'.
        sns.heatmap(table.fillna(0), annot=True, fmt=".1f", cmap="YlOrRd", cbar_kws={'label': 'Completeness %'})
        plt.title("Echocardiogram Triage Matrix: Data Presence as a Function of Disease Severity", fontsize=15)
        plt.xlabel("Clinician-Assessed Severity (Ordinal Scale)")
        plt.ylabel("Echocardiographic Parameter by Pathology")
        plt.show()

    def complexity_frequency(self):
        """
        Visualizes the phenotypic burden of the cohort.
        """
        plt.figure(figsize=(10, 6))
        
        # Count frequencies of each score
        counts = self.df['Complexity_Score'].value_counts().sort_index()
        
        # Create a bar plot
        sns.barplot(x=counts.index, y=counts.values, hue=counts.index, palette="YlOrRd", legend=False)
        
        plt.title("Distribution of Patient Complexity Scores", fontsize=15)
        plt.xlabel("Complexity Score (0 = Simple, 5+ = Highly Complex)", fontsize=12)
        plt.ylabel("Number of Patients", fontsize=12)
        
        # Add labels on top of bars
        for i, val in enumerate(counts.values):
            plt.text(i, val + 0.5, str(val), ha='center', fontsize=11, fontweight='bold')
            
        plt.grid(axis='y', linestyle='--', alpha=0.7)
        plt.show()

    def complexity_markers(self, markers_list):
        """
        Shows the prevalence of specific complexity markers.
        """
        prevalence = self.df[markers_list].sum().sort_values(ascending=False)
        
        plt.figure(figsize=(10, 6))
        prevalence.plot(kind='barh', color='#e34a33')
        plt.title("Prevalence of Complexity Markers", fontsize=15)
        plt.xlabel("Patient Count", fontsize=12)
        plt.gca().invert_yaxis()
        plt.show()

    def complexity_heatmap(self, interaction_cols):
        # Interaction Analysis: Identifying 'Syndromic Clusters' where multiple pathologies co-exist, increasing clinical risk.
        
        # Calculate the correlation (co-occurrence)
        # We use 'pearson' here to see how strongly one predicts the other
        interaction_matrix = self.df[interaction_cols].corr()

        plt.figure(figsize=(10, 8))
        sns.heatmap(interaction_matrix, annot=True, cmap='RdBu_r', center=0, fmt=".2f")
        
        plt.title("Clinical Interaction Heatmap: Pathological Clustering", fontsize=15)
        plt.tight_layout()
        plt.show()

class Statistics:
    def __init__(self, dataframe, config):
        self.df = dataframe.copy()
        self.config = config

    def impute_normal(self, target_col):
        """
        Implements 'Brigade Logic': Missing values are assumed normal, 
        but filled with Gaussian noise to preserve dataset variance.
        """
        temp_df = self.df.copy()
        temp_df[target_col] = pd.to_numeric(temp_df[target_col], errors='coerce')
        
        mask = temp_df[target_col].isnull()
        num_missing = mask.sum()
        
        if num_missing > 0:
            # SPECIAL CASE: Discrete Scores (like LA_Size_Score)
            if target_col == 'LA_Size_Score':
                # Fill missing with 0.0 (Normal) for 95% of cases and 1.0 (Mild) for 5%
                choices = [0.0, 1.0]
                probabilities = [0.95, 0.05]
                temp_df.loc[mask, target_col] = np.random.choice(choices, size=num_missing, p=probabilities)
                
            # CONTINUOUS CASE: Standard echo measurements
            else:
                mean, std = self.config.normal_variables.get(target_col, (0, 1))
                simulated_normals = np.random.normal(mean, std, size=num_missing)
                temp_df.loc[mask, target_col] = np.clip(simulated_normals, 0, None)
                
        return temp_df[target_col]

class Pipeline:
    def __init__(self, raw_df, config):
        self.config = config
        self.df = raw_df.copy()
        # Storage for components so we can access their internal reports
        self.auditor = None
        self.extractor = None
        self.calculator = None
        self.visualizer = None

    def sequence(self):
        """Orchestrates the entire flow in the correct clinical order."""

    # --- PHASE 1: AUDIT (Goals 1, 2, 3, 4) ---
        print(f"PHASE 1: Baseline Integrity Audit\n{'='*40}")
        self.auditor = Auditor(self.df, self.config)
        self.audit_report = self.auditor.report() # Prints categories & missingness
        
        # --- PHASE 2: EXTRACTION & PROFILING (Goals 7, 9) ---
        print(f"\nPHASE 2: Clinical Extraction & Profiling\n{'='*40}")
        self.extractor = Extractor(self.df, self.config)
        self.df = self.extractor.transform()
        self.df = self.extractor.disease_profiler()
        
        # Re-sync the auditor with the new columns (Sev_MS, etc.) for the Triage Matrix
        self.auditor.df = self.df

        # Triage Matrix (Goal 7)
        self.triage_matrix = self.auditor.echo_missingness() 
        print(self.triage_matrix)

        # --- PHASE 3: CALCULATION (Goal 9) ---
        self.calculator = Calculator(self.df, self.config)
        self.df = self.calculator.medication_index()
        print(f"\nPHASE 3: CALCULATION\n{'='*40}")
        print("Medication Burden Index (MBI) generated...")

        # --- PHASE 4: VISUALIZATION (Goals 5, 6, 8, 10) ---
        print(f"\nPHASE 4: Generating Clinical Visuals\n{'='*40}")
        self.visualizer = Visualizer(self.df)
        
        # Missingness Visuals (Goal 5, 6, 8)
        self.visualizer.patient_nullity(self.config.echo_vars)
        self.visualizer.echo_matrix(self.triage_matrix)
        
        # Complexity Visuals (Goal 10)
        self.visualizer.complexity_frequency()
        complexity_markers = ['Mixed_Mitral', 'Mixed_Aortic', 'Multi_Valve', 'Has_Shunt', 'AFib_Present']
        self.visualizer.complexity_markers(complexity_markers)
        self.visualizer.complexity_heatmap(complexity_markers)

        # --- PHASE 5: FINAL REPORTING ---
        self.summary()
        
        return self.df
    
    def summary(self):
        """
        Final output for Brigade Leadership. 
        Summarizes volume, complexity, and resource burden.
        """
        if self.df is None or 'Complexity_Score' not in self.df.columns:
            print("Error: Please run 'sequence()' before generating a report.")
            return
        
        total = len(self.df)
        high_risk_pct = (self.df['Complexity_Score'] >= 2).mean() * 100
        avg_mbi = self.df['MBI'].mean()
        
        # Use the stored extractor to get pathology counts
        # We handle cases where Anatomy_Pre might be empty
        try:
            top_pathology = self.df['Anatomy_Pre'].str.split(', ').explode().mode()[0]
        except (KeyError, IndexError):
            top_pathology = "Data not available"

        # 1. Gets the specific disease prevalence and complex conditions 
        prevalence = self.extractor.diagnoses_prevalence()
        stats = self.extractor.complexity_stats

        print(f"""
        {"="*45}
        BRIGADE EXECUTIVE SUMMARY: PHL 2025
        {"="*45}
        1. PATIENT VOLUME: {total} total evaluations performed.
        2. CLINICAL BURDEN: {high_risk_pct:.1f}% of the cohort presented with 
        Complex/Multi-valvular disease profiles.
        3. DOMINANT PATHOLOGY: {top_pathology} was the most frequent finding.
        4. MEDICATION BURDEN: Mean MBI is {avg_mbi:.2f}. 
        (A higher score indicates greater pharmacological dependency).
        """)
        print(f"""{"="*45}\nDISEASE PREVALENCE BREAKDOWN\n{"="*45}""")
        print(prevalence)
        print(f"""\n* DOCUMENTATION FIDELITY: Triage Matrix and Audit Logs generated.\n{"="*45}
        """)

        pass
```


```python
# Setup
config = ClinicalConfig()
raw_data = pd.read_csv('phl_2025.csv')

# Execute
pipeline = Pipeline(raw_data, config)
processed_df = pipeline.sequence()

# Visualize
viz = Visualizer(processed_df)
```

    PHASE 1: Baseline Integrity Audit
    ========================================
    Current columns by category:
    ----------------------------------------
    Demographics/Vitals: ['Age', 'Gender', 'Weight', 'Height', 'OSat', 'SBP R', 'DBP R', 'Heart rate']
    Medications: ['Medications']
    Clinical Context: ['Pre-procedure diagnosis', 'Post-procedure diagnosis', 'Year(s) since procedure']
    Structural Echo (Dimensions): ['IVSd', 'LVIDd', 'LVPWd', 'LVIDs', 'Aortic root', 'Left atrium measure', 'Left atrium']
    Functional Echo (Hemodynamics): ['LVEF (categorical)', 'RVSP', 'TR Vmax', 'AO V1 max', 'AO V2 max', 'MS MG (mmHg)']
    
    Mean missingness by category (%):
    ----------------------------------------
    Demographics/Vitals                0.58% missing
    Medications                        8.55% missing
    Clinical Context                  46.05% missing
    Structural Echo (Dimensions)      81.77% missing
    Functional Echo (Hemodynamics)    66.89% missing
    dtype: object
    
    Audit report generated:
    ----------------------------------------
    Technical metadata file generated: dataset_audit_report.csv. 
    All unique diagnoses list generated: all_diagnoses_report.csv.
    All medications list generated: all_medications_report.csv.
    
    PHASE 2: Clinical Extraction & Profiling
    ========================================
    Triage proxy pivot table
    ----------------------------------------
    Rows: Pathology-Parameter pairs
    Columns: Clinical Severity (0.0 to 3.5)
    
    Severity                 0.0    1.0     2.0    3.0    3.5
    Pathology Parameter                                      
    AR        AO V1 max      6.47    NaN   20.00  25.00   NaN
              AO V2 max     16.55    NaN    0.00  37.50   NaN
              Aortic root   14.39    NaN   60.00  37.50   NaN
              IVSd          19.42    NaN   20.00  62.50   NaN
              LVPWd         15.83    NaN   20.00  62.50   NaN
    AS        AO V1 max      3.39    NaN    0.00  18.18  40.0
              AO V2 max      5.93    NaN   50.00  63.64  40.0
              Aortic root   10.17    NaN   50.00  40.91  40.0
              IVSd          17.80    NaN   50.00  27.27  50.0
              LVPWd         16.10    NaN   50.00  27.27  20.0
    MR        LVIDd         23.13   0.00   50.00  30.77   NaN
              LVIDs         18.66   0.00   25.00  30.77   NaN
              Left atrium   13.43   0.00   25.00  30.77   NaN
              MS MG (mmHg)  20.90   0.00   75.00  30.77   NaN
    MS        LVIDd         30.48   0.00    0.00  11.90   NaN
              LVIDs         23.81   0.00    0.00  11.90   NaN
              Left atrium    5.71  33.33   50.00  35.71   NaN
              MS MG (mmHg)   1.90  33.33  100.00  71.43   NaN
    PH        RVSP          29.41  66.67    0.00  90.00   NaN
              TR Vmax       13.97  33.33   33.33  50.00   NaN
    
    PHASE 3: CALCULATION
    ========================================
    Medication Burden Index (MBI) generated...
    
    PHASE 4: Generating Clinical Visuals
    ========================================
    


    <Figure size 1000x600 with 0 Axes>



    
![png](phl_2025_1_files/phl_2025_1_3_2.png)
    


    Correlation of Missingness (1.0 = Always missing together):
    ----------------------------------------
    


    
![png](phl_2025_1_files/phl_2025_1_3_4.png)
    


    
    Echocardiogram Triage Matrix notes:
    ----------------------------------------
    A 'Hot' cell (High %) indicates a parameter the cardiologist deemed mandatory for triage.
    


    
![png](phl_2025_1_files/phl_2025_1_3_6.png)
    



    
![png](phl_2025_1_files/phl_2025_1_3_7.png)
    



    
![png](phl_2025_1_files/phl_2025_1_3_8.png)
    



    
![png](phl_2025_1_files/phl_2025_1_3_9.png)
    


    
            =============================================
            BRIGADE EXECUTIVE SUMMARY: PHL 2025
            =============================================
            1. PATIENT VOLUME: 152 total evaluations performed.
            2. CLINICAL BURDEN: 3.9% of the cohort presented with 
            Complex/Multi-valvular disease profiles.
            3. DOMINANT PATHOLOGY: Mitral stenosis was the most frequent finding.
            4. MEDICATION BURDEN: Mean MBI is 2.86. 
            (A higher score indicates greater pharmacological dependency).
            
    =============================================
    DISEASE PREVALENCE BREAKDOWN
    =============================================
    Mitral stenosis                                                 49
    Aortic stenosis                                                 34
    Secundum atrial septal defect                                   22
    Mitral regurgitation                                            19
    Pulmonary hypertension                                          15
    Aortic regurgitation                                            15
    Surgical aortic valve replacement                               14
    Bicuspid aortic valve                                           12
    Mitral valve percutaneous valvuloplasty                         11
    Atrial fibrillation                                              9
    Tricuspid regurgitation                                          8
    Surgical mitral valve replacement                                8
    Perimembranous ventricular septal defect                         7
    Surgical repair of atrial septal defect                          5
    Atrial septal defect                                             5
    Persistent ductus arteriosus                                     4
    Mitral valve prolapse                                            4
    Aortic coarctation                                               4
    Dilated aortic root                                              3
    Left atrium thrombus                                             3
    Percutaneous persistent ductus arteriosus closure                3
    Intracavitary right ventricle muscle bundle with obstruction     2
    Arrhythmogenic right ventricle dysplasia                         2
    Primary pulmonary hypertension                                   2
    Left atrium myxoma                                               2
    Congenital pulmonary stenosis                                    2
    Stable angina                                                    2
    Wolf-parkinson-white                                             2
    Tricuspid valve atresia                                          2
    Dilated cardiomyopathy                                           2
    Sinus of valsalva aneurysm                                       1
    Dilated left ventricle                                           1
    Hypothyroidism                                                   1
    Aortic arch hypoplasia                                           1
    Malalignment ventricular septal defect                           1
    Persistent left-sided superior vena cava                         1
    Pulmonary regurgitation                                          1
    Class 3 stable angina                                            1
    Dual chamber permanent pacemaker                                 1
    Left ventricle dilation                                          1
    Refractory angina                                                1
    Right ventricular dilation                                       1
    Ventricular septal defect                                        1
    Incomplete atrioventricular septal defect                        1
    Partial endocardial cushion defect                               1
    Stunned myocardium from rapid ventricular response               1
    Patent ductus arteriosus                                         1
    Dysplastic mitral valve                                          1
    Heart failure with reduced ejection fraction                     1
    Myxoma                                                           1
    Unicusp aortic valve                                             1
    Calcific aortic stenosis                                         1
    Sinus venosus atrial septal defect                               1
    Stroke                                                           1
    Right ventricular hypertrophy                                    1
    Left ventricular hypertrophy                                     1
    Ascending aorta aneurysm                                         1
    Persistent left superior vena cava to coronary sinus             1
    Miocardial infarction                                            1
    Stent placement                                                  1
    Surgical tricuspid repair                                        1
    Pulmonary stenosis                                               1
    Aortic valvotomy                                                 1
    Failed ablation                                                  1
    Glenn shunt procedure                                            1
    Severely dilated cardiomyopathy                                  1
    Surgical mitral valvuloplasty                                    1
    Myxoma resection                                                 1
    Pericardial patch placement                                      1
    Surgical closure with patch                                      1
    Secondary chordal rupture                                        1
    Graft for ascending aorta                                        1
    Name: count, dtype: int64
    
    * DOCUMENTATION FIDELITY: Triage Matrix and Audit Logs generated.
    =============================================
            
    


```python
# '''Step 6:'''
# for var in clinical_config.echo_missing:
#     if var in stat.df.columns:
#         # Use 'Natural Normal' to respect Brigade Logic while keeping variance
#         stat.df[f'{var}_Imputed'] = stat.impute_normal(var)
#         print(f"Handled {var} using 'Natural Normal' distribution.")

# df_final = stat.df
```


```python
# # 1. Initialize
# targets = ['RVSP', 'LVIDd', 'LA_Size_Score', 'LVEF_Score']

# # 2. Impute and compare
# for var in targets:
#     if var in df_final.columns:
#         stat.df[f'{var}_Imputed'] = stat.impute_normal(var)

# # 3. Visualization: Continuous Hemodynamics (RVSP)
# plt.figure(figsize=(12, 5))
# plt.subplot(1, 2, 1)
# sns.kdeplot(df_final['RVSP'].dropna(), label='Measured (Sick)', color='red', fill=True)
# sns.kdeplot(df_final['RVSP_Imputed'], label='Cohort (Measured + Assumed)', color='green', linestyle='--')
# plt.title("RVSP: Hemodynamic Shift")
# plt.legend()

# # 4. Visualization: Discrete Anatomy (LA Size)
# plt.subplot(1, 2, 2)
# # Count the frequencies for the imputed vs original
# original_counts = df_final['LA_Size_Score'].value_counts(normalize=True).sort_index()
# imputed_counts = df_final['LA_Size_Score_Imputed'].value_counts(normalize=True).sort_index()

# width = 0.35
# x = np.arange(len(imputed_counts))

# plt.bar(x - width/2, original_counts.reindex(imputed_counts.index, fill_value=0), width, label='Measured', color='darkred')
# plt.bar(x + width/2, imputed_counts, width, label='Cohort', color='seagreen')

# plt.xticks(x, imputed_counts.index)
# plt.title("LA Size Score: Population Burden")
# plt.legend()
# plt.tight_layout()
# plt.show()
```


```python
# # ==========================================
# # ROC ANALYSIS: MBI as a Predictor of Complexity
# # ==========================================

# # 1. Redefining Target: Capturing 'Rising Risk' (Score 1 or higher)
# # We use the imputed dataframe to ensure the denominator includes the whole cohort
# df_final['Is_Complex_Case'] = (df_final['Complexity_Score'] >= 1).astype(int)

# # 2. Recalculate ROC Metrics
# # We are testing how well MBI (Medication Burden) predicts Clinical Complexity
# fpr, tpr, thresholds = roc_curve(df_final['Is_Complex_Case'], df_final['MBI'])
# roc_auc = auc(fpr, tpr)

# # 3. Finding the Optimal Cutoff using Youden's J statistic
# # This identifies the point where Sensitivity and Specificity are maximized
# j_scores = tpr - fpr
# best_idx = np.argmax(j_scores)
# best_cutoff = thresholds[best_idx]

# # 4. Visualization
# plt.figure(figsize=(10, 7))
# plt.plot(fpr, tpr, color='#e34a33', lw=3, label=f'ROC curve (AUC = {roc_auc:.2f})')
# plt.plot([0, 1], [0, 1], color='#bdbdbd', linestyle='--', label='Random Classifier')
# plt.scatter(fpr[best_idx], tpr[best_idx], color='black', s=100, zorder=5,
#             label=f'Optimal MBI Cutoff: {best_cutoff:.2f}')

# plt.xlabel('False Positive Rate (1 - Specificity)')
# plt.ylabel('True Positive Rate (Sensitivity)')
# plt.title('Predictive Power: Medication Burden vs. Clinical Complexity', fontsize=14)
# plt.legend(loc='lower right')
# plt.grid(alpha=0.3)
# plt.show()

# print(f"Analysis Complete: An MBI above {best_cutoff:.2f} is the best predictor of patient complexity.")
```


```python
# 5. EXPLORATIONS
# ==========================================

# # 1. Identify the maximum severity across all tracked pathologies for each patient
# pathology_cols = ['Sev_MS', 'Sev_MR', 'Sev_AS', 'Sev_AR', 'Sev_PH']
# calculated['Max_Pathology_Severity'] = calculated[pathology_cols].max(axis=1)

# # 2. Refine the Discordance Mask
# # True Discordance = High Meds AND (No single pathology is > Moderate)
# true_discordance_mask = (
#     (calculated['MBI'] >= 5.0) & 
#     (calculated['Max_Pathology_Severity'] <= 2.0)
# )

# # 3. Label the groups for visualization
# calculated['Discordance_Type'] = 'Matched'
# calculated.loc[(calculated['MBI'] >= 5.0) & (calculated['Max_Pathology_Severity'] > 2.0), 'Discordance_Type'] = 'Explained High Burden'
# calculated.loc[true_discordance_mask, 'Discordance_Type'] = 'True Discordance (TEE Priority)'

# print(calculated['Discordance_Type'].value_counts())

# # Create a Stratified Discordance Table
# stratified_discordance = pd.crosstab(
#     calculated['Approach'], 
#     calculated['Discordance_Type'], 
#     normalize='index'
# ) * 100

# print("Percentage of Discordance by Clinical Approach:")
# print(stratified_discordance.round(2))

# # Filter for intervened patients only
# intervened = calculated[calculated['Approach'] != 'Native'].copy()

# # Compare MBI and RVSP across intervention types
# comparison = intervened.groupby('Approach').agg({
#     'MBI': ['mean', 'std', 'max'],
#     'Max_Pathology_Severity': 'mean'
# }).round(2)

# print("\nSurgical Audit: Residual Burden by Intervention Type")
# print(comparison)

# # 1. Redefining Target: Capturing 'Rising Risk' (Score 1 or higher)
# calculated['Is_Complex_Case'] = (calculated['Complexity_Score'] >= 1).astype(int)

# # 2. Recalculate ROC Metrics
# fpr, tpr, thresholds = roc_curve(calculated['Is_Complex_Case'], calculated['MBI'])
# roc_auc = auc(fpr, tpr)

# # 3. Finding the Optimal Cutoff
# j_scores = tpr - fpr
# best_idx = np.argmax(j_scores)
# best_cutoff = thresholds[best_idx]

# # 4. Visualization
# plt.figure(figsize=(10, 7))
# plt.plot(fpr, tpr, color='#e34a33', lw=3, label=f'ROC curve (AUC = {roc_auc:.2f})')
# plt.plot([0, 1], [0, 1], color='grey', linestyle='--')
# plt.scatter(fpr[best_idx], tpr[best_idx], color='black', s=100, 
#             label=f'Optimal MBI Cutoff: {best_cutoff:.2f}')

# plt.xlabel('False Positive Rate')
# plt.ylabel('True Positive Rate')
# plt.title('ROC: MBI vs. Complexity Score >= 1 (Rising Risk)', fontsize=14)
# plt.legend()
# plt.show()

# print(f"Total Complex Cases (Score >= 1): {final_df['Is_Complex_Case'].sum()} out of {len(final_df)}")
```


```python
# plt.figure(figsize=(12, 8))

# sns.scatterplot(
#     data=calculated,
#     x='Max_Pathology_Severity',
#     y='MBI',
#     hue='Discordance_Type',
#     style='Discordance_Type',
#     palette={'Matched': 'grey', 'Explained High Burden': 'blue', 'True Discordance (TEE Priority)': 'red'},
#     s=100,
#     alpha=0.7
# )

# plt.axhline(y=5.0, color='black', linestyle='--', alpha=0.3)
# plt.title("MBI vs. Global Cardiac Severity: Identifying Unexplained Clinical Burden", fontsize=15)
# plt.xlabel("Maximum Severity Score (Any Pathology)", fontsize=12)
# plt.ylabel("Medication Burden Index (MBI)", fontsize=12)
# plt.grid(True, alpha=0.2)
# plt.show()
```


```python
# 6. LOG OF CURRENT STATUS OF CODE
# ==========================================
file = 'phl_2025_1.ipynb'
os.system(f"jupyter nbconvert --to markdown {file}")
print(f"Success! Markdown file generated: {file.replace('.ipynb', '.md')}")

```

    Success! Markdown file generated: phl_2025_1.md
    
