{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9316099",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import seaborn as sns\n",
    "import re\n",
    "\n",
    "# ==========================================\n",
    "# 1. DICTIONARIES\n",
    "# ==========================================\n",
    "columns_selected = {\n",
    "    'demographics' : ['Age', 'Gender', 'Weight', 'Height'],\n",
    "    'mitral_metrics' : ['MR gradient', 'MS PHT', 'PHT area', 'MSA planimetry', 'MS MG (mmHg)'],\n",
    "    'remodeling' : ['Left atrium', 'RV size', 'RV function', 'RVSP', 'TR Grading'],\n",
    "    'lv_function' : ['LVEF (categorical)', 'LVIDd', 'LVIDs'],\n",
    "    'clinical_context' : ['Pre-procedure diagnosis', 'Post-procedure diagnosis', 'Year(s) since procedure', 'Medications'],\n",
    "    'vitals' : ['SBP L', 'DBP L', 'SBP R', 'DBP R', 'Heart rate', 'OSat']\n",
    "}\n",
    "drug_classes = {\n",
    "    'Beta_Blockers': ['Carvedilol', 'Bisoprolol', 'Metoprolol', 'Propranolol', 'Atenolol'],\n",
    "    'RAAS_Inhibitors': ['Enalapril', 'Lisinopril', 'Losartan', 'Irbesartan', 'Captopril', 'Sacubitril-valsartan'],\n",
    "    'Diuretics_Loop': ['Furosemide'],\n",
    "    'Diuretics_Other': ['Spironolactone', 'Hydrochlorothiazide'],\n",
    "    'Anticoagulants': ['Warfarin', 'Rivaroxaban', 'Apixaban', 'Aspirin', 'Clopidogrel'],\n",
    "    'Rate_Control': ['Digoxin', 'Amiodarone'],\n",
    "    'SGLT2_Inhibitors': ['Dapaglifozin', 'Empaglifozin'],\n",
    "    'Pulm_Vasodilators': ['Sildenafil', 'Tadalafil']\n",
    "}\n",
    "drug_freq = {'qd': 1, 'bid': 2, 'tid': 3, 'qid': 4}\n",
    "index_severity = {'Mild': 1, 'Moderate': 2, 'Severe': 3, 'critical': 3}\n",
    "\n",
    "# ==========================================\n",
    "# 2. FUNCTIONS\n",
    "# ==========================================\n",
    "class data_transformer:\n",
    "    def __init__(self, dataframe):\n",
    "        self.df = dataframe.copy()\n",
    "\n",
    "    @classmethod\n",
    "    def raw_data(cls, raw_df, config_dict):\n",
    "        selected_columns = [col for sublist in config_dict.values() for col in sublist]\n",
    "        available_columns = [col for col in selected_columns if col in raw_df.columns]\n",
    "        \n",
    "        total_raw_cols = raw_df.shape[1]\n",
    "        total_selected = len(available_columns)\n",
    "        total_rows = raw_df.shape[0]\n",
    "\n",
    "        print(f\"{'='*30}\")\n",
    "        print(\"DATA ACCOUNTING REPORT\")\n",
    "        print(f\"{'='*30}\")\n",
    "        print(f\"Rows processed:     {total_rows}\")\n",
    "        print(f\"Columns in source:  {total_raw_cols}\")\n",
    "        print(f\"Columns selected:   {total_selected}\")\n",
    "\n",
    "        missing = set(selected_columns) - set(available_columns)\n",
    "        if missing:\n",
    "            print(f\"Status: Missing {len(missing)} expected columns.\")\n",
    "            print(f\"Dropped: {list(missing)}\")\n",
    "        else:\n",
    "            print(f\"Status: All expected columns matched successfully.\")\n",
    "\n",
    "        return cls(raw_df[available_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30194732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "DATA ACCOUNTING REPORT\n",
      "==============================\n",
      "Rows processed:     152\n",
      "Columns in source:  67\n",
      "Columns selected:   27\n",
      "Status: All expected columns matched successfully.\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# 3. EXECUTION\n",
    "# ==========================================\n",
    "df = pd.read_csv('phl_2025.csv')\n",
    "transformer = data_transformer.raw_data(df, columns_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3ee8b55b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "DATA ACCOUNTING REPORT\n",
      "==============================\n",
      "Rows: 152 | Columns Matched: 27\n",
      "\n",
      "==============================\n",
      "LESION LANDSCAPE AUDIT\n",
      "==============================\n",
      "ms_sev    47\n",
      "mr_sev    19\n",
      "as_sev    34\n",
      "ar_sev    15\n",
      "ph_sev    16\n",
      "dtype: int64\n",
      "\n",
      "Double valvular (Mitral) Patients: 8\n",
      "Double valvular (Aortic) Patients: 2\n",
      "Multivalvular (Mitral + Aortic) Patients: 9\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# ==========================================\n",
    "# 1. ENHANCED CONFIGURATION\n",
    "# ==========================================\n",
    "# We use floats to respect the \"Gray Areas\" for more precise regressions\n",
    "SEVERITY_GRADES = {\n",
    "    'mild': 1.0,\n",
    "    'mild to moderate': 1.5,\n",
    "    'moderate': 2.0,\n",
    "    'moderate to severe': 2.5,\n",
    "    'severe': 3.0,\n",
    "    'critical': 3.0\n",
    "}\n",
    "\n",
    "# The \"Big Five\" Hemodynamic Drivers\n",
    "PATHOLOGY_TARGETS = {\n",
    "    'ms': 'mitral stenosis',\n",
    "    'mr': 'mitral regurgitation',\n",
    "    'as': 'aortic stenosis',\n",
    "    'ar': 'aortic regurgitation',\n",
    "    'ph': 'pulmonary hypertension'\n",
    "}\n",
    "\n",
    "# ==========================================\n",
    "# 2. DATA TRANSFORMER\n",
    "# ==========================================\n",
    "class DataTransformer:\n",
    "    def __init__(self, dataframe):\n",
    "        self.df = dataframe.copy()\n",
    "\n",
    "    @classmethod\n",
    "    def raw_data(cls, raw_df, config_dict):\n",
    "        \"\"\"Standardizes columns and initializes row accounting.\"\"\"\n",
    "        selected_columns = [col for sublist in config_dict.values() for col in sublist]\n",
    "        available_columns = [col for col in selected_columns if col in raw_df.columns]\n",
    "        \n",
    "        print(f\"{'='*30}\\nDATA ACCOUNTING REPORT\\n{'='*30}\")\n",
    "        print(f\"Rows: {raw_df.shape[0]} | Columns Matched: {len(available_columns)}\")\n",
    "        \n",
    "        missing = set(selected_columns) - set(available_columns)\n",
    "        if missing: print(f\"Dropped/Missing: {list(missing)}\")\n",
    "        \n",
    "        return cls(raw_df[available_columns].copy())\n",
    "\n",
    "    def _parse_severity(self, text, target):\n",
    "        \"\"\"Regex-based segment parser for 'Gray Area' preservation.\"\"\"\n",
    "        if pd.isna(text): return 0.0\n",
    "        segments = text.lower().split(';')\n",
    "        \n",
    "        found_grade = 0.0\n",
    "        for seg in segments:\n",
    "            if target in seg:\n",
    "                # Search for the longest keys first (e.g., 'moderate to severe' before 'moderate')\n",
    "                sorted_keys = sorted(SEVERITY_GRADES.keys(), key=len, reverse=True)\n",
    "                for key in sorted_keys:\n",
    "                    if key in seg:\n",
    "                        found_grade = max(found_grade, SEVERITY_GRADES[key])\n",
    "        return found_grade\n",
    "\n",
    "    def build_pathology_matrix(self):\n",
    "        \"\"\"Parses all valves and PH into float-based severity columns.\"\"\"\n",
    "        self.df['diag_text'] = (\n",
    "            self.df['Pre-procedure diagnosis'].fillna('') + ';' + \n",
    "            self.df['Post-procedure diagnosis'].fillna('')\n",
    "        ).str.lower()\n",
    "\n",
    "        for col_prefix, search_term in PATHOLOGY_TARGETS.items():\n",
    "            self.df[f'{col_prefix}_sev'] = self.df['diag_text'].apply(\n",
    "                lambda x: self._parse_severity(x, search_term)\n",
    "            )\n",
    "        return self\n",
    "\n",
    "    def extract_medication_burden(self, drug_classes):\n",
    "        \"\"\"Calculates Drug Count as a baseline for Cardio Burden.\"\"\"\n",
    "        self.df['med_count'] = self.df['Medications'].fillna('').apply(\n",
    "            lambda x: len([m for m in x.split('|') if m.strip()]) if x else 0\n",
    "        )\n",
    "        return self\n",
    "\n",
    "    def flag_complex_congenital(self):\n",
    "        \"\"\"Identifies heterogeneous pathologies that might confound remodeling.\"\"\"\n",
    "        congenital_terms = ['asd', 'vsd', 'coarctation', 'ductus', 'bicuspid', 'septal defect']\n",
    "        self.df['is_complex'] = self.df['diag_text'].str.contains('|'.join(congenital_terms)).astype(int)\n",
    "        return self\n",
    "\n",
    "    def run_eda_pipeline(self, drug_classes):\n",
    "        \"\"\"Sequence of operations for the EDA phase.\"\"\"\n",
    "        return (self.build_pathology_matrix()\n",
    "                .extract_medication_burden(drug_classes)\n",
    "                .flag_complex_congenital()\n",
    "                .df)\n",
    "\n",
    "# ==========================================\n",
    "# 3. EXECUTION & EDA AUDIT\n",
    "# ==========================================\n",
    "# Assuming df is loaded\n",
    "transformer = DataTransformer.raw_data(df, columns_selected)\n",
    "eda_df = transformer.run_eda_pipeline(drug_classes)\n",
    "\n",
    "# THE EDA AUDIT: Identifying the \"True\" Lesion Landscape\n",
    "print(f\"\\n{'='*30}\\nLESION LANDSCAPE AUDIT\\n{'='*30}\")\n",
    "lesion_counts = (eda_df[[f'{c}_sev' for c in PATHOLOGY_TARGETS.keys()]] > 0).sum()\n",
    "print(lesion_counts)\n",
    "\n",
    "# Identify Multivalvular Involvement\n",
    "mmd = ((eda_df['ms_sev'] > 0) & (eda_df['mr_sev'] > 0))\n",
    "mad = ((eda_df['as_sev'] > 0) & (eda_df['ar_sev'] > 0))\n",
    "mvd_mask = ((eda_df['ms_sev'] > 0) | (eda_df['mr_sev'] > 0)) & \\\n",
    "           ((eda_df['as_sev'] > 0) | (eda_df['ar_sev'] > 0))\n",
    "print(f\"\\nDouble valvular (Mitral) Patients: {mmd.sum()}\")\n",
    "print(f\"Double valvular (Aortic) Patients: {mad.sum()}\")\n",
    "print(f\"Multivalvular (Mitral + Aortic) Patients: {mvd_mask.sum()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_phl (3.12.4)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
